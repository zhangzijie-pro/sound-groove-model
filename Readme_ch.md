
---

# ğŸ™ï¸ å£°çº¹ Grooveï¼šåŸºäº ECAPA-TDNN çš„è¯´è¯äººéªŒè¯ç³»ç»Ÿ

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub stars](https://img.shields.io/github/stars/zhangzijie-pro/Speaker-Verification.svg?style=social)](https://github.com/zhangzijie-pro/Speaker-Verification/stargazers)
[![Hugging Face](https://img.shields.io/badge/HuggingFace-æ¨¡å‹%20%26%20æ•°æ®é›†-yellow.svg)](https://huggingface.co/zzj-pro)
![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c?logo=pytorch)
![Task](https://img.shields.io/badge/Task-Speaker%20Verification-green)

<div align="center">
  <a href="README.md">English</a> â€¢ 
  <a href="https://github.com/zhangzijie-pro/Speaker-Verification">GitHub</a> â€¢ 
  <a href="https://huggingface.co/zzj-pro">Hugging Face</a>
</div>

> ä¸€ä¸ªå®ç”¨ä¸”é«˜æ•ˆçš„**ä¸­æ–‡è¯´è¯äººéªŒè¯ç³»ç»Ÿ**ï¼ŒåŸºäº **ECAPA-TDNN + AAM-Softmax**ï¼Œåœ¨ **CN-Celeb** æ•°æ®é›†ä¸Šè®­ç»ƒä¸è¯„ä¼°ã€‚

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **SOTA ä¸»å¹²ç½‘ç»œ**ï¼šECAPA-TDNNï¼ˆRes2Net + SE + æ³¨æ„åŠ›ç»Ÿè®¡æ± åŒ–ï¼‰
- **å¼ºåˆ¤åˆ«æŸå¤±**ï¼šAAM-Softmaxï¼ˆå¸¦è§’åº¦è¾¹è·ï¼‰
- **å‡è¡¡é‡‡æ ·**ï¼šPK Batch Samplerï¼ˆè¯´è¯äººå‡è¡¡ï¼‰
- **å®Œæ•´è¯„ä¼°ä½“ç³»**ï¼šEERã€åˆ†æ•°åˆ†å¸ƒã€t-SNEã€Recall@K
- **ç¨³å®šæ¨ç†**ï¼šå¤šæ®µè£å‰ªå¹³å‡ï¼ˆcrop-averageï¼‰
- **ä½æ˜¾å­˜ä¼˜åŒ–**ï¼šä¸“ä¸º â‰ˆ6GB GPU è®¾è®¡ï¼ˆAMP + æ¢¯åº¦è£å‰ªï¼‰

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
Speaker-Verification/
â”œâ”€â”€ CN-Celeb_flac/Â  Â  Â  Â  Â  # Original CN-Celeb dataset (FLAC/WAV)
â”‚
â”œâ”€â”€ processed/Â  Â  Â  Â  Â  Â  Â  # Preprocessed features & metadata
â”‚ Â  â””â”€â”€ cn_celeb2/
â”‚ Â  Â  Â  â”œâ”€â”€ fbank_pt/ Â  Â  Â  # Saved fbank features (*.pt)
â”‚ Â  Â  Â  â”œâ”€â”€ train_fbank_list.txt
â”‚ Â  Â  Â  â”œâ”€â”€ val_meta.jsonlÂ  # Validation metadata (speaker, feature path)
â”‚ Â  Â  Â  â””â”€â”€ spk2id.json
â”‚
â”œâ”€â”€ configs/
â”‚ Â  â”œâ”€â”€ train.yaml
â”‚ Â  â””â”€â”€ train_config.py Â  Â  # Training hyperparameters
â”‚
â”œâ”€â”€ demos/
â”‚ Â  â””â”€â”€ app.pyÂ  Â  Â  Â  Â  Â  Â  # gradio web to test
â”‚
â”œâ”€â”€ data/
â”‚ Â  â”œâ”€â”€ dataset.pyÂ  Â  Â  Â  Â  # Train / validation datasets
â”‚ Â  â””â”€â”€ pk_sampler.py Â  Â  Â  # PK batch sampler (speaker-balanced)
â”‚
â”œâ”€â”€ models/
â”‚ Â  â””â”€â”€ ecapa.pyÂ  Â  Â  Â  Â  Â  # ECAPA-TDNN implementation
â”‚
â”œâ”€â”€ loss_head/
â”‚ Â  â””â”€â”€ aamsoftmax.py Â  Â  Â  # AAM-Softmax loss
â”‚
â”œâ”€â”€ utils/
â”‚ Â  â”œâ”€â”€ meters.py Â  Â  Â  Â  Â  # Accuracy, average meters
â”‚ Â  â”œâ”€â”€ seed.py Â  Â  Â  Â  Â  Â  # Reproducibility
â”‚ Â  â”œâ”€â”€ plot.py Â  Â  Â  Â  Â  Â  # Training curves
â”‚ Â  â”œâ”€â”€ path_utils.py Â  Â  Â  # Deal to path error
â”‚ Â  â””â”€â”€ audio.pyÂ  Â  Â  Â  Â  Â  # audio process utils
â”‚
â”œâ”€â”€ scripts/
â”‚ Â  â””â”€â”€ export.py Â  Â  Â  Â  Â  # export onnx/mnn and split model, head
â”‚
â”œâ”€â”€ outputs/Â  Â  Â  Â  Â  Â  Â  Â  # Training outputs (checkpoints, curves)
â”œâ”€â”€ outputs_eval/ Â  Â  Â  Â  Â  # Verification results (EER, ROC, DET, t-SNE)
â”‚
â”œâ”€â”€ train.pyÂ  Â  Â  Â  Â  Â  Â  Â  # Main training script
â”œâ”€â”€ verify_pairs.py Â  Â  Â  Â  # Pairwise speaker verification
â”œâ”€â”€ compare_two_wavs.py Â  Â  # Compare two audio files
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ README_ch.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
git clone https://github.com/zhangzijie-pro/Speaker-Verification.git
cd Speaker-Verification
pip install -r requirements.txt
```

### 2. æ•°æ®é¢„å¤„ç†

```bash
python processed/preprocess_cnceleb2_train.py
```

### 3. è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python train.py

# å‘½ä»¤è¡Œè¦†ç›–å‚æ•°
python train.py train.epochs=100 train.lr=5e-4 train.emb_dim=256
```

---

## ğŸ“ˆ è¯„ä¼°ï¼ˆè¯´è¯äººéªŒè¯ï¼‰

### å®Œæ•´è¯„ä¼°

```bash
python verify.py \
    --val_meta processed/cn_celeb2/val_meta.jsonl \
    --ckpt outputs/best.pt \
    --out_dir outputs_eval
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `roc.png`ã€`det.png`ã€`score_hist.png`
- `tsne.png`ï¼ˆè¯´è¯äººèšç±»å¯è§†åŒ–ï¼‰
- `metrics.txt`ï¼ˆEERã€Recall@K ç­‰æŒ‡æ ‡ï¼‰

---

## ğŸ¯ å•æ¡éŸ³é¢‘å¯¹æ¯”ï¼ˆæœ€å¸¸ç”¨åœºæ™¯ï¼‰

```bash
python compare_two_wavs.py \
    --wav1 test1.wav \
    --wav2 test2.wav \
    --ckpt outputs/export/model.onnx   # æ”¯æŒ ONNX
```

---

## ğŸ› ï¸ æ¨¡å‹å¯¼å‡ºï¼ˆéƒ¨ç½²ï¼‰

```bash
# ä¸€é”®å¯¼å‡º ONNX + MNN
python scripts/export.py \
    --ckpt outputs/best.pt \
    --out_dir outputs/deploy \
    --onnx --mnn
```

**æ”¯æŒçš„éƒ¨ç½²æ–¹å¼**ï¼š
- **ONNX Runtime**ï¼ˆPython / C++ï¼‰
- **MNN**ï¼ˆç§»åŠ¨ç«¯ / è¾¹ç¼˜è®¾å¤‡ï¼‰
- **TensorRT**ï¼ˆé«˜æ€§èƒ½æœåŠ¡å™¨ï¼‰

---

## ğŸ§  æ¨¡å‹æ¦‚è§ˆ

### ä¸»å¹²ç½‘ç»œ

- **ECAPA-TDNN**
  - Res2Net é£æ ¼æ—¶åŸŸå·ç§¯
  - Squeeze-and-Excitationï¼ˆSEï¼‰
  - æ³¨æ„åŠ›ç»Ÿè®¡æ± åŒ–ï¼ˆAttentive Statistics Poolingï¼‰
- åµŒå…¥ç»´åº¦ï¼š**192 / 256**

### æŸå¤±å‡½æ•°

- **AAM-Softmaxï¼ˆåŠ æ€§è§’åº¦è¾¹è· Softmaxï¼‰**
  - å¢å¤§è¯´è¯äººä¹‹é—´çš„è§’åº¦è¾¹è·
  - ä»…åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨

### åµŒå…¥è¡¨ç¤º

- L2 å½’ä¸€åŒ–è¯´è¯äººåµŒå…¥
- ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡ŒéªŒè¯

---

## ğŸ“Š æ•°æ®é›†

- **CN-Celeb**
  - â‰ˆ1000 åè¯´è¯äºº
  - å½•éŸ³æ¡ä»¶é«˜åº¦å¤šæ ·
- æ•°æ®åˆ’åˆ†ï¼š
  - `train`ï¼šè¯´è¯äººä¸é‡å çš„è®­ç»ƒé›†
  - `val`ï¼šè¯´è¯äººä¸é‡å çš„éªŒè¯é›†
- ç‰¹å¾ï¼š
  - 80 ç»´ log Mel æ»¤æ³¢å™¨ç»„
  - 16kHz é‡‡æ ·ç‡

---

## ğŸ“Œ æ¨èé…ç½®ï¼ˆ6GB GPUï¼‰

```yaml
# configs/train.yaml
emb_dim: 256
channels: 512
lr: 1e-3
epochs: 80
crop_frames: 200          # è®­ç»ƒæ—¶è£å‰ªé•¿åº¦
crop_frames_val: 400      # éªŒè¯æ—¶è£å‰ªé•¿åº¦
num_crops: 6
p: 32
k: 4
```

---

## ğŸ”® æœªæ¥æ”¹è¿›è®¡åˆ’

- [x] Hydra é…ç½®ç®¡ç†
- [x] å¹¶è¡Œé¢„å¤„ç†è„šæœ¬
- [x] ONNX / MNN å¯¼å‡º
- [ ] å™ªå£° / RIR æ•°æ®å¢å¼º

---

## ğŸ“œ å¼€æºåè®®

æœ¬é¡¹ç›®é‡‡ç”¨ **Apache License 2.0** å¼€æºåè®®ã€‚  
CN-Celeb æ•°æ®é›†éµå¾ªå…¶åŸå§‹è®¸å¯åè®®å’Œä½¿ç”¨æ¡æ¬¾ã€‚

---

## ğŸ™‹ è¯´æ˜

æœ¬ä»“åº“ä¸»è¦ç”¨äºï¼š

- å­¦ä¹ è¯´è¯äººéªŒè¯ç³»ç»Ÿ
- ç§‘ç ”å¤ç°ä¸äºŒæ¬¡å¼€å‘

**ä¸æ˜¯å¼€ç®±å³ç”¨çš„å•†ç”¨ç³»ç»Ÿ**ã€‚
