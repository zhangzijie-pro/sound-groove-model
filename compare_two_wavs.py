import argparse
import torch
import numpy as np
from pathlib import Path

try:
    import onnxruntime as ort
    _HAS_ONNX = True
except ImportError:
    _HAS_ONNX = False
    print("âš ï¸ onnxruntime æœªå®‰è£…ï¼ŒONNX æ¨¡å¼ä¸å¯ç”¨ã€‚")
    print("   pip install onnxruntime  æˆ–  onnxruntime-gpu")

from models.ecapa import ECAPA_TDNN
from utils.audio import load_wav_mono, wav_to_fbank


@torch.no_grad()
def embed_wav_pt(model, wav_path: str, device: torch.device) -> torch.Tensor:
    wav = load_wav_mono(wav_path, target_sr=16000)      # [T]
    feat = wav_to_fbank(wav, n_mels=80)                 # [T_frames, 80]
    x = feat.unsqueeze(0).to(device)                    # [1, T, 80]
    emb = model(x).squeeze(0).cpu()                     # [D]
    emb = emb / (emb.norm() + 1e-12)                    # L2 normalize
    return emb


def embed_wav_onnx(session: ort.InferenceSession, wav_path: str) -> np.ndarray:
    wav = load_wav_mono(wav_path, target_sr=16000)
    feat = wav_to_fbank(wav, n_mels=80)                 # [T, 80]
    feat = feat.unsqueeze(0).numpy().astype(np.float32) # [1, T, 80]

    # ONNX è¾“å…¥åé€šå¸¸æ˜¯ "fbank"ï¼ˆä½ åœ¨ export.py é‡Œè®¾ç½®çš„ï¼‰
    input_name = session.get_inputs()[0].name
    outputs = session.run(None, {input_name: feat})

    emb = outputs[0][0]                                 # [D]
    emb = emb / (np.linalg.norm(emb) + 1e-12)           # L2 normalize
    return emb


def main():
    parser = argparse.ArgumentParser(description="ä¸¤ä¸ªéŸ³é¢‘è¯´è¯äººå¯¹æ¯”ï¼ˆPyTorch / ONNXï¼‰")
    
    parser.add_argument("--wav1", type=str, required=True, help="ç¬¬ä¸€ä¸ªéŸ³é¢‘è·¯å¾„")
    parser.add_argument("--wav2", type=str, required=True, help="ç¬¬äºŒä¸ªéŸ³é¢‘è·¯å¾„")
    
    parser.add_argument("--ckpt", type=str, default="outputs/export/model.onnx",
                        help="æ¨¡å‹è·¯å¾„ï¼š.pt (PyTorch) æˆ– .onnx (ONNX)")
    
    parser.add_argument("--onnx", action="store_true", default=False,
                        help="ä½¿ç”¨ ONNX æ¨ç†ï¼ˆé»˜è®¤è‡ªåŠ¨æ ¹æ®æ–‡ä»¶åç¼€åˆ¤æ–­ï¼‰")
    
    parser.add_argument("--threshold", type=float, default=0.55,
                        help="åˆ¤æ–­åŒä¸€äººçš„ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆå»ºè®®é€šè¿‡ verify.py å¾—åˆ°æœ€ä½³é˜ˆå€¼ï¼‰")
    
    parser.add_argument("--device", type=str, default="cuda", choices=["cuda", "cpu"],
                        help="PyTorch æ¨¡å¼ä½¿ç”¨çš„è®¾å¤‡ï¼ˆONNX é»˜è®¤ CPUï¼‰")

    args = parser.parse_args()

    ckpt_path = Path(args.ckpt)
    use_onnx = args.onnx or ckpt_path.suffix.lower() == ".onnx"

    print("=" * 70)
    print("ğŸ™ï¸  Speaker Verification - Two Wavs Comparison")
    print("=" * 70)
    print(f"Audio 1 : {args.wav1}")
    print(f"Audio 2 : {args.wav2}")
    print(f"Model   : {ckpt_path}  ({'ONNX' if use_onnx else 'PyTorch'})")
    print(f"Threshold: {args.threshold}")
    print("=" * 70)

    if use_onnx:
        if not _HAS_ONNX:
            raise ImportError("è¯·å…ˆå®‰è£… onnxruntime: pip install onnxruntime")

        print("ä½¿ç”¨ ONNX Runtime æ¨ç†...")
        session = ort.InferenceSession(
            str(ckpt_path),
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"] if torch.cuda.is_available() else ["CPUExecutionProvider"]
        )

        e1 = embed_wav_onnx(session, args.wav1)
        e2 = embed_wav_onnx(session, args.wav2)
        score = float(np.dot(e1, e2))

    else:
        device = torch.device(args.device if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨ PyTorch æ¨ç† (device: {device})")

        ckpt = torch.load(ckpt_path, map_location="cpu")
        model = ECAPA_TDNN(
            in_channels=80,
            channels=512,
            embd_dim=256
        ).to(device)

        model.load_state_dict(ckpt["model"], strict=True)
        model.eval()

        e1 = embed_wav_pt(model, args.wav1, device)
        e2 = embed_wav_pt(model, args.wav2, device)
        score = float(torch.sum(e1 * e2).item())

    # ==================== è¾“å‡º ====================
    same = score >= args.threshold

    print(f"\nğŸ” Cosine Similarity = {score:.4f}")
    print(f"   Threshold        = {args.threshold}")
    print(f"   â†’ {'åŒä¸€è¯´è¯äºº' if same else 'ä¸åŒè¯´è¯äºº'}")

    color = "\033[92m" if same else "\033[91m"
    print(f"\n{color}ã€æœ€ç»ˆåˆ¤å®šã€‘{'âœ… åŒä¸€äºº' if same else 'âŒ ä¸åŒäºº'}\033[0m")

    print("\n" + "=" * 70)


if __name__ == "__main__":
    main()